
x-ollama-base: &ollama-base
  image: ollama/ollama:latest
  container_name: ollama-container
  env_file:
    - .env.gpu-auto
  depends_on:
    env-setup:
      condition: service_completed_successfully
  volumes:
    - ollama_data:/root/.ollama
  restart: unless-stopped
  networks:
    - ollama-network

services:
  env-setup:
    image: mcr.microsoft.com/powershell:lts-alpine-3.14
    restart: "no"
    volumes:
      - .:/workspace
    working_dir: /workspace
    command: |
      pwsh -c "
        Write-Host '🔧 Cross-platform environment setup starting...' -ForegroundColor Cyan;
        
        # Early exit if both files exist
        if ((Test-Path '.env') -and (Test-Path '.env.gpu-auto')) {
          Write-Host '✅ Both .env and .env.gpu-auto already exist, skipping setup' -ForegroundColor Green;
          exit 0;
        }

        # Copy .env file
        if (Test-Path '.env') {
          Write-Host '.env already exists, skipping copy' -ForegroundColor Green;
        } else {
          Write-Host 'Copying .env from example...' -ForegroundColor Yellow;
          Copy-Item '.env.example' '.env';
        }
        
        # Cross-platform GPU detection
        if (Test-Path '.env.gpu-auto') {
          Write-Host '.env.gpu-auto already exists, skipping copy' -ForegroundColor Green;
        } else {
          Write-Host '🔍 Detecting GPU capabilities...' -ForegroundColor Cyan;
          $$IsCUDACapable = $$false;
          
          try {
              # Check for NVIDIA devices in /proc (Linux/WSL2)
              if (Test-Path '/proc/driver/nvidia') {
                  $$IsCUDACapable = $$true;
                  Write-Host 'GPU detected via /proc/driver/nvidia' -ForegroundColor Gray;
              }
              # Check for NVIDIA devices in /dev
              elseif (Test-Path '/dev/nvidia0') {
                  $$IsCUDACapable = $$true;
                  Write-Host 'GPU detected via /dev/nvidia0' -ForegroundColor Gray;
              }
              # Check for nvidia-smi
              elseif (Get-Command nvidia-smi -ErrorAction SilentlyContinue) {
                  try {
                      $$result = & nvidia-smi --query-gpu=name --format=csv,noheader 2>$$null;
                      if ($$LASTEXITCODE -eq 0 -and $$result) {
                          $$IsCUDACapable = $$true;
                          Write-Host 'GPU detected via nvidia-smi' -ForegroundColor Gray;
                      }
                  } catch {
                      Write-Host 'nvidia-smi failed' -ForegroundColor Gray;
                  }
              }
              # Check for CUDA runtime
              elseif (Test-Path '/usr/local/cuda') {
                  $$IsCUDACapable = $$true;
                  Write-Host 'GPU detected via CUDA installation' -ForegroundColor Gray;
              }
          } catch {
              Write-Host 'GPU detection error, defaulting to CPU' -ForegroundColor Gray;
          }
          
          if ($$IsCUDACapable) {
              Write-Host '🚀 NVIDIA GPU detected - configuring GPU mode' -ForegroundColor Green;
              Copy-Item .env.gpu.example .env.gpu-auto
          } else {
              Write-Host '💻 No GPU detected - configuring CPU mode' -ForegroundColor Yellow;
              Copy-Item .env.cpu.example .env.gpu-auto
          }
        }

        Write-Host '✅ Configuration complete' -ForegroundColor Green;
      "
    networks:
      - ollama-network

  ollama-cpu:
    <<: *ollama-base
    profiles:
      - cpu

  ollama-gpu:
    <<: *ollama-base
    profiles:
      - gpu
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    depends_on:
      env-setup:
        condition: service_completed_successfully
    ports:
      - "${OPENWEBUI_PORT:-3000}:8080"
    env_file:
      - .env
    volumes:
      - openwebui_data:/app/backend/data
    restart: unless-stopped
    networks:
      - ollama-network

volumes:
  ollama_data:
  openwebui_data:

networks:
  ollama-network:
    driver: bridge
